{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Mental Health Datahton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "from io import BytesIO\n",
    "import difflib\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from contextlib import redirect_stdout\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from textblob import TextBlob\n",
    "from typing import Tuple, Dict, Any\n",
    "import pyspssio\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture print outputs\n",
    "def capture_print(func, filename):\n",
    "    f = io.StringIO()\n",
    "    with redirect_stdout(f):\n",
    "        func()\n",
    "    output = f.getvalue()\n",
    "    if output.strip(): \n",
    "        with open(f'text_outputs/{filename}.txt', 'w') as file:\n",
    "            file.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Guarding Minds .SAV file\n",
    "file_path = 'input/Mental Health Research Canada/Guarding Minds - Mental Health in the Workplace/Guarding minds 2023_weighted_15.6.2023 Final.sav'\n",
    "df, meta = pyspssio.read_sav(file_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of rows: {df.shape[0]}, Number of columns: {df.shape[1]}\")\n",
    "\n",
    "# Display column names\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Display data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to explore and apply SPSS metadata\n",
    "def process_spss_metadata(df, meta):\n",
    "    print(f\"Dataset has {len(df.columns)} variables\")\n",
    "    \n",
    "    # 1. Create a data dictionary\n",
    "    var_info = []\n",
    "    for col in df.columns:\n",
    "        info = {\n",
    "            'variable': col,\n",
    "            'label': meta.get('var_labels', {}).get(col, ''),\n",
    "            'values': meta.get('var_value_labels', {}).get(col, {}),\n",
    "            'type': meta.get('var_types', {}).get(col, ''),\n",
    "            'measure': meta.get('var_measure_levels', {}).get(col, '')\n",
    "        }\n",
    "        var_info.append(info)\n",
    "    \n",
    "    data_dict = pd.DataFrame(var_info)\n",
    "    \n",
    "    # 2. Create versions of the DataFrame\n",
    "    # Original with variable attributes\n",
    "    for col in df.columns:\n",
    "        if col in meta.get('var_labels', {}):\n",
    "            df[col].attrs['label'] = meta['var_labels'][col]\n",
    "        if col in meta.get('var_value_labels', {}):\n",
    "            df[col].attrs['value_labels'] = meta['var_value_labels'][col]\n",
    "    \n",
    "    # Version with readable column names\n",
    "    labeled_columns_df = df.copy()\n",
    "    labeled_columns_df.columns = [meta.get('var_labels', {}).get(col, col) for col in df.columns]\n",
    "    \n",
    "    # Version with values replaced by labels - UPDATED APPROACH\n",
    "    labeled_values_df = df.copy()\n",
    "    for col, labels in meta.get('var_value_labels', {}).items():\n",
    "        if col in labeled_values_df.columns:\n",
    "            # Using apply with lambda instead of map+fillna\n",
    "            labeled_values_df[col] = labeled_values_df[col].apply(\n",
    "                lambda x: labels.get(x, x) if pd.notna(x) else x\n",
    "            )\n",
    "    \n",
    "    return {\n",
    "        'original': df,\n",
    "        'data_dictionary': data_dict,\n",
    "        'labeled_columns': labeled_columns_df,\n",
    "        'labeled_values': labeled_values_df\n",
    "    }\n",
    "\n",
    "# Apply the function to your data\n",
    "results = process_spss_metadata(df, meta)\n",
    "\n",
    "# Extract each component into separate variables for easier access\n",
    "original_df = results['original']  # Original DataFrame with attributes\n",
    "data_dictionary = results['data_dictionary']  # Data dictionary with variable info\n",
    "labeled_columns_df = results['labeled_columns']  # DataFrame with human-readable column names\n",
    "labeled_values_df = results['labeled_values']  # DataFrame with human-readable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about each component\n",
    "print(\"\\n=== Original DataFrame ===\")\n",
    "print(f\"Shape: {original_df.shape}\")\n",
    "print(original_df.head())\n",
    "\n",
    "print(\"\\n=== Data Dictionary ===\")\n",
    "print(f\"Number of variables: {len(data_dictionary)}\")\n",
    "print(data_dictionary.head())\n",
    "\n",
    "print(\"\\n=== DataFrame with Labeled Columns ===\")\n",
    "print(f\"Shape: {labeled_columns_df.shape}\")\n",
    "print(labeled_columns_df.head())\n",
    "\n",
    "print(\"\\n=== DataFrame with Labeled Values ===\")\n",
    "print(f\"Shape: {labeled_values_df.shape}\")\n",
    "print(labeled_values_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all columns and save column names along with their data types to csv\n",
    "def save_column_names_to_csv(df, df_type):\n",
    "    filename = f\"text_outputs/guarding_minds/{df_type}_survey_columns.csv\"\n",
    "    \n",
    "    # Create a DataFrame with the column names and their data types\n",
    "    column_info = pd.DataFrame({\n",
    "        'Column Names': df.columns,\n",
    "        'Data Type': [df.dtypes[col] for col in df.columns]\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    column_info.to_csv(filename, index=False)\n",
    "    print(f\"\\nColumn names and data types have been saved to {filename}\")\n",
    "    \n",
    "save_column_names_to_csv(df, 'original')\n",
    "save_column_names_to_csv(labeled_columns_df, 'labeled_columns')\n",
    "save_column_names_to_csv(labeled_values_df, 'labeled_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your processed data for future use\n",
    "original_df.to_pickle('processed_data/guarding_minds/original_df.pkl')\n",
    "data_dictionary.to_csv('processed_data/guarding_minds/data_dictionary.csv', index=False)\n",
    "labeled_columns_df.to_pickle('processed_data/guarding_minds/labeled_columns_df.pkl')\n",
    "labeled_values_df.to_pickle('processed_data/guarding_minds/labeled_values_df.pkl')\n",
    "\n",
    "print(\"\\nAll processed datasets have been saved to the 'processed_data' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set specific guarding minds output path\n",
    "output_path = 'plot_outputs/guarding_minds'\n",
    "\n",
    "# missing values heatmap\n",
    "def plot_missing_values_heatmap(df, output_path):\n",
    "    plt.figure(figsize=(40, 20))\n",
    "    sns.heatmap(df.isnull(), yticklabels=False, cbar=True, cmap='viridis')\n",
    "    plt.title('Missing Values Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/missing_values_heatmap.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_missing_values_heatmap(labeled_values_df, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value percentages\n",
    "def plot_missing_values_bars(df, output_path):\n",
    "    plt.figure(figsize=(20, 36))\n",
    "    missing_percentages = (df.isnull().sum() / len(df) * 100).sort_values(ascending=True)\n",
    "    sns.barplot(x=missing_percentages.values, y=missing_percentages.index)\n",
    "    plt.title('Percentage of Missing Values by Column')\n",
    "    plt.xlabel('Percentage Missing')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/missing_values_percentage.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_missing_values_bars(labeled_values_df, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with 'Missing' for every object column and convert to category type\n",
    "labeled_values_df_columns = labeled_values_df.columns\n",
    "\n",
    "for c in labeled_values_df_columns:\n",
    "    if labeled_values_df[c].dtype == \"object\":\n",
    "        # Step 1: Replace NaN values with 'Missing'\n",
    "        labeled_values_df[c] = labeled_values_df[c].fillna(\"Missing\")\n",
    "        \n",
    "        # Step 2: Convert the column from object type to category type\n",
    "        labeled_values_df[c] = labeled_values_df[c].astype('category')\n",
    "        \n",
    "        # Optional: Print conversion confirmation for debugging\n",
    "        print(f\"Column '{c}' converted to category with dtype: {labeled_values_df[c].dtype}\")\n",
    "\n",
    "# Print summary of categorical features\n",
    "print(f\"In these features, there are {len(labeled_values_df_columns)} CATEGORICAL FEATURES: {labeled_values_df_columns}\")\n",
    "\n",
    "# Optional: Print memory usage improvement\n",
    "print(f\"Memory usage after conversion: {labeled_values_df.memory_usage().sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot categorical distributions\n",
    "def plot_categorical_distributions(df, output_path):\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    for col in tqdm.tqdm(categorical_cols, desc=\"Creating categorical plots\"):\n",
    "        if df[col].nunique() < 30:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            value_counts = df[col].value_counts()\n",
    "            sns.barplot(x=value_counts.index, y=value_counts.values)\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_path}/categorical_{col}.png')\n",
    "            plt.close()\n",
    "\n",
    "# labeled values data frame\n",
    "plot_categorical_distributions(labeled_values_df, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical distributions\n",
    "def plot_numerical_distributions(df, output_path):\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns\n",
    "    \n",
    "    # Create progress bar for numerical distributions\n",
    "    for col in tqdm.tqdm(numerical_cols, desc=\"Creating distribution plots\"):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create subplot with histogram and kde\n",
    "        sns.histplot(data=df, x=col, kde=True)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        # Add statistical annotations\n",
    "        stats_text = f'Mean: {df[col].mean():.2f}\\n'\n",
    "        stats_text += f'Median: {df[col].median():.2f}\\n'\n",
    "        stats_text += f'Std: {df[col].std():.2f}'\n",
    "        plt.text(0.95, 0.95, stats_text,\n",
    "                transform=plt.gca().transAxes,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_path}/distribution_{col}.png')\n",
    "        plt.close()\n",
    "\n",
    "# numerical distributions of labeled values\n",
    "plot_numerical_distributions(labeled_values_df, output_path)\n",
    "\n",
    "# numerical distributions of original\n",
    "plot_numerical_distributions(df, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each province\n",
    "province_counts = labeled_values_df['PROV'].value_counts().reset_index()\n",
    "province_counts.columns = ['province_code', 'count']\n",
    "\n",
    "# Print the counts to verify\n",
    "print(\"Province counts:\")\n",
    "print(province_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix Newfoundland label\n",
    "province_counts['province_code'] = province_counts['province_code'].astype(str)\n",
    "province_counts.loc[province_counts['province_code'] == 'Newfoundland', 'province_code'] = 'Newfoundland and Labrador'\n",
    "province_counts['province_code'] = province_counts['province_code'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get canada geojson file\n",
    "canada_geojson_url = \"https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/canada.geojson\"\n",
    "canada_geojson_response = requests.get(canada_geojson_url)\n",
    "canada_geojson = json.loads(canada_geojson_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base map\n",
    "canada_map = folium.Map(location=[56.1304, -106.3468], zoom_start=3, \n",
    "                       tiles='CartoDB positron')\n",
    "\n",
    "# Add choropleth layer\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data=canada_geojson,\n",
    "    name='choropleth',\n",
    "    data=province_counts,\n",
    "    columns=['province_code', 'count'],\n",
    "    key_on='feature.properties.name',\n",
    "    fill_color='YlOrRd',  # Yellow-Orange-Red color scheme\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    legend_name='Number of occurrences in PROV column',\n",
    "    highlight=True\n",
    ").add_to(canada_map)\n",
    "\n",
    "# Add tooltips to the choropleth layer\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['name'], labels=False)\n",
    ")\n",
    "\n",
    "# Add a layer control\n",
    "folium.LayerControl().add_to(canada_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in province_counts.iterrows():\n",
    "    # Find the matching province in the GeoJSON\n",
    "    for feature in canada_geojson['features']:\n",
    "        if feature['properties']['name'] == row['province_code']:\n",
    "            # Get approximate center of the province\n",
    "            geometry = feature['geometry']\n",
    "            if geometry['type'] == 'Polygon':\n",
    "                # For simple polygons\n",
    "                coords = np.array(geometry['coordinates'][0])\n",
    "                center = coords.mean(axis=0)\n",
    "                # Folium expects coordinates as [lat, lon]\n",
    "                center = [center[1], center[0]]\n",
    "            elif geometry['type'] == 'MultiPolygon':\n",
    "                # For complex shapes with multiple polygons\n",
    "                all_coords = []\n",
    "                for polygon in geometry['coordinates']:\n",
    "                    coords = np.array(polygon[0])\n",
    "                    all_coords.append(coords)\n",
    "                all_coords = np.vstack(all_coords)\n",
    "                center = all_coords.mean(axis=0)\n",
    "                center = [center[1], center[0]]\n",
    "            else:\n",
    "                # Skip if geometry type is unexpected\n",
    "                continue\n",
    "                \n",
    "            # Add a circle marker with count information\n",
    "            folium.CircleMarker(\n",
    "                location=center,\n",
    "                radius=int(np.sqrt(row['count']) * 0.3),  # Scale the radius based on count\n",
    "                popup=f\"{row['province_code']}: {row['count']} occurrences\",\n",
    "                color='#3186cc',\n",
    "                fill=True,\n",
    "                fill_color='#3186cc',\n",
    "                fill_opacity=0.7\n",
    "            ).add_to(canada_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a simple legend in the corner\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 250px; height: auto; \n",
    "            border:2px solid grey; z-index:9999; font-size:14px;\n",
    "            background-color:white;\n",
    "            padding: 10px;\n",
    "            border-radius: 5px;\n",
    "           \">\n",
    "    <div style=\"font-weight: bold; margin-bottom: 5px;\">Province Count Legend</div>\n",
    "'''\n",
    "\n",
    "# Add entries for each province in descending order\n",
    "for _, row in province_counts.sort_values('count', ascending=False).iterrows():\n",
    "    legend_html += f'<div>{row[\"province_code\"]}: {row[\"count\"]}</div>'\n",
    "\n",
    "legend_html += '</div>'\n",
    "\n",
    "# Add the legend as an HTML element\n",
    "canada_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Save the map to an HTML file\n",
    "canada_map.save('plot_outputs/guarding_minds/canada_province_heatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
